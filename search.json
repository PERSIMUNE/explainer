[{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to explainer","title":"Contributing to explainer","text":"outlines propose change explainer. detailed info contributing , tidyverse packages, please see development contributing guide.","code":""},{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to explainer","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to explainer","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reprex (also help write unit test, needed).","code":""},{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to explainer","text":"Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"PERSIMUNE/explainer\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style described https://style.tidyverse.org/news.html.","code":""},{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to explainer","text":"New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://persimune.github.io/explainer/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to explainer","text":"Please note explainer project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://persimune.github.io/explainer/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 explainer authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"introduction-to-explainer-package","dir":"Articles","previous_headings":"","what":"Introduction to Explainer Package","title":"explainer-vignette","text":"vignette serves basic introduction functionalities Explainer package. Explainer provides comprehensive toolkit explaining interpreting machine learning models.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"shapclust","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"SHAPclust","title":"explainer-vignette","text":"function used SHAP clustering binary classification models. SHAP values calculated eSHAP_plot function used cluster data samples (instances) using k-means method identify subgroups individuals specific patterns feature contributions.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"shapfeatureplot","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"ShapFeaturePlot","title":"explainer-vignette","text":"function can sued plot SHAP values association feature values.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"shappartialplot","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"ShapPartialPlot","title":"explainer-vignette","text":"function generates interactive partial dependence plot based SHAP values, visualizing marginal effect one two features predicted outcome machine learning model.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"ecm_plot","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eCM_plot","title":"explainer-vignette","text":"function generates enhanced confusion matrix plot using CVMS package. plot includes visualizations sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV).","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"edecisioncurve","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eDecisionCurve","title":"explainer-vignette","text":"Decision curve analysis statistical method used medical research evaluate compare clinical utility different diagnostic predictive models. assesses net benefit model across range decision thresholds, aiding selection informative practical approach guiding clinical decisions.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"efairness","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eFairness","title":"explainer-vignette","text":"function generates Precision-Recall ROC curves sample subgroups, facilitating fairness analysis binary classification model.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"eperformance","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eperformance","title":"explainer-vignette","text":"function generates Precision-Recall ROC curves, including threshold information binary classification models.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"eroc_plot","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eROC_plot","title":"explainer-vignette","text":"function generates Precision-Recall ROC curves binary classification models.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"eshap_plot","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eSHAP_plot","title":"explainer-vignette","text":"function generates SHAP summary plot classification models. visualization tool uses Shapley value, approach cooperative game theory, compute feature contributions single predictions. Shapley value fairly distributes difference instance’s prediction datasets average prediction among features. method available iml package. See package tutorial working example binary classification model analysis.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"eshap_plot_multiclass","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eSHAP_plot_multiclass","title":"explainer-vignette","text":"function extension eSHAP_plot function multiclass classification. See package tutorial working example multi-class classification model analysis.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"eshap_plot_reg","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"eSHAP_plot_reg","title":"explainer-vignette","text":"function creates SHAP summary plot regression model. See package tutorial working example regression model analysis.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"range01","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"range01","title":"explainer-vignette","text":"function used scale data range 0 1. uses Hampel filter adjust outliers, followed min-max normalization.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer-vignette.html","id":"regressmdl_eval","dir":"Articles","previous_headings":"Introduction to Explainer Package > Functions Overview","what":"regressmdl_eval","title":"explainer-vignette","text":"function provides calculations measures evaluate regression models.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-loading-a-dataset-and-training-a-machine-learning-model","dir":"Articles","previous_headings":"","what":"Loading a dataset and training a machine learning model","title":"classification model interpretation using explainer package","text":"first code chunk loads dataset creates binary classification task train “random forest” model using mlr3 package.","code":"Sys.setenv(LANG = \"en\") # change R language to English! RNGkind(\"L'Ecuyer-CMRG\") # change to L'Ecuyer-CMRG in case it uses default \"Mersenne-Twister\"  library(\"explainer\") # set seed for reproducibility seed <- 246 set.seed(seed)  # load the BreastCancer data from the mlbench package data(\"BreastCancer\", package = \"mlbench\")  # keep the target column as \"Class\" target_col <- \"Class\"  # change the positive class to \"malignant\" positive_class <- \"malignant\"      # keep only the predictor variables and outcome mydata <- BreastCancer[, -1] # 1 is ID  # remove rows with missing values mydata <- na.omit(mydata)  # create a vector of sex categories sex <- sample(c(\"Male\", \"Female\"), size = nrow(mydata), replace = TRUE)  # create a vector of sex categories mydata$age <- as.numeric(sample(seq(18,60), size = nrow(mydata), replace = TRUE))  # add a sex column to the mydata data frame (for fairness analysis) mydata$sex <- factor(sex, levels = c(\"Male\", \"Female\"), labels = c(1, 0))   # create a classification task maintask <- mlr3::TaskClassif$new(id = \"my_classification_task\",                                   backend = mydata,                                   target = target_col,                                   positive = positive_class)  # create a train-test split set.seed(seed) splits <- mlr3::partition(maintask)  # add a learner (machine learning model base) # library(\"mlr3learners\") # library(\"mlr3extralearners\")  # mlr_learners$get(\"classif.randomForest\") # here we use random forest for example (you can use any other available model) # mylrn <- mlr3::lrn(\"classif.randomForest\", predict_type = \"prob\") library(\"mlr3learners\") ## Loading required package: mlr3 mylrn <- mlr3::lrn(\"classif.ranger\", predict_type = \"prob\")  # train the model mylrn$train(maintask, splits$train)  # make predictions on new data mylrn$predict(maintask, splits$test) ##  ## -- <PredictionClassif> for 225 observations: ----------------------------------- ##  row_ids     truth  response prob.malignant prob.benign ##        2    benign malignant     0.86798175  0.13201825 ##        5    benign    benign     0.00922619  0.99077381 ##        7    benign    benign     0.35852381  0.64147619 ##      ---       ---       ---            ---         --- ##      671    benign    benign     0.00000000  1.00000000 ##      675    benign    benign     0.00230000  0.99770000 ##      681 malignant malignant     0.91511905  0.08488095"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-shap-analysis-to-extract-feature-variable-impacts-on-predictions","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"SHAP analysis to extract feature (variable) impacts on predictions","title":"classification model interpretation using explainer package","text":"following code chunk uses eSHAP_plot function estimate SHAP values test set create interactive SHAP plot. enhanced SHAP plot means provides additional information whether predictions correct (TP TN). color mapping provides enhanced visual inspection SHAP plot. following plot displays SHAP values associate predicted probabilities.","code":"library(\"magrittr\") library(\"plotly\") ## Loading required package: ggplot2 ##  ## Attaching package: 'plotly' ## The following object is masked from 'package:ggplot2': ##  ##     last_plot ## The following object is masked from 'package:stats': ##  ##     filter ## The following object is masked from 'package:graphics': ##  ##     layout # enhanced SHAP plot SHAP_output <- eSHAP_plot(task = maintask,            trained_model = mylrn,            splits = splits,            sample.size = 30,            seed = seed,            subset = .8)  # display the SHAP plot myplot <- SHAP_output[[1]] myplot SHAP_output[[5]] ## `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-visualize-model-performance-by-confusion-matrix","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"Visualize model performance by confusion matrix","title":"classification model interpretation using explainer package","text":"following code chunk uses eCM_plot function visualize confusion matrix evaluate model performance train test sets. information can found : https://en.wikipedia.org/wiki/Confusion_matrix https://cran.r-project.org/web/packages/cvms/vignettes/Creating_a_confusion_matrix.html","code":"# enhanced confusion matrix confusionmatrix_plot <- eCM_plot(task = maintask,          trained_model = mylrn,          splits = splits) ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'ggimage' is missing. Will not plot arrows and ## zero-shading. ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'rsvg' is missing. Will not plot arrows and ## zero-shading. ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'ggnewscale' is missing. Will not use palette ## for sum tiles. ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'ggimage' is missing. Will not plot arrows and ## zero-shading. ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'rsvg' is missing. Will not plot arrows and ## zero-shading. ## Warning in cvms::plot_confusion_matrix(cfm, target_col = \"Truth\", ## prediction_col = \"Prediction\", : 'ggnewscale' is missing. Will not use palette ## for sum tiles. print(confusionmatrix_plot) ## $train_set ##  ## $test_set"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-decision-curve-analysis","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"Decision curve analysis","title":"classification model interpretation using explainer package","text":"provided code chunk employs eDecisionCurve function conduct “decision curve analysis” test set within model. -depth understanding methodology, interested readers encouraged explore following authoritative references: Decision Curve Analysis: https://en.wikipedia.org/wiki/Decision_curve_analysis “Decision curve analysis: novel method evaluating prediction models” Andrew J. Vickers Elia B. Elkin. Link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2577036/ references offer comprehensive insights principles applications decision curve analysis, providing solid foundation exploration understanding methodology employed presented code.","code":"# enhanced decision curve plot eDecisionCurve(task = maintask,          trained_model = mylrn,          splits = splits,          seed = seed)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-model-evaluation-multi-metrics-and-visual-inspection-of-roc-curves","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"Model evaluation (multi-metrics and visual inspection of ROC curves)","title":"classification model interpretation using explainer package","text":"running next code chunk, get following model evaluation metrics visualizations: AUC (Area Curve): AUC quantifies binary classification model’s performance assessing area ROC curve, plots sensitivity 1-specificity across various threshold values. value 0.5 suggests random chance performance, 1 signifies perfect classification. BACC (Balanced Accuracy): BACC addresses class imbalance averaging sensitivity specificity. Ranging 0 1, score 0 indicates chance performance, 1 signifies perfect classification. MCC (Matthews Correlation Coefficient): MCC evaluates binary classification model quality, considering true positives, true negatives, false positives, false negatives. Ranging -1 1, -1 represents complete disagreement, 0 implies chance performance, 1 indicates perfect classification. BBRIER (Brier Score): BBRIER gauges accuracy probabilistic predictions measuring mean squared difference predicted probabilities true binary outcomes. Values range 0 1, 0 indicating perfect calibration 1 indicating poor calibration. PPV (Positive Predictive Value): PPV, precision, measures proportion true positive predictions positive predictions made model. NPV (Negative Predictive Value): NPV quantifies proportion true negative predictions negative predictions made model. Specificity: Specificity calculates proportion true negative predictions actual negative cases binary classification problem. Sensitivity: Sensitivity, also known recall true positive rate, measures proportion true positive predictions actual positive cases binary classification problem. PRAUC (Precision-Recall Area Curve): PRAUC assesses binary classification model performance based precision recall, quantifying area precision-recall curve. PRAUC value 1 indicates perfect classification performance. Additionally, analysis involves visualization ROC Precision-Recall curves development test sets.","code":"eROC_plot(task = maintask,          trained_model = mylrn,          splits = splits) ## [[1]] ##  ## [[2]] ##             pred_results$score(measures = mlr3::msrs(meas)) ## auc                                                    1.00 ## bacc                                                   0.99 ## mcc                                                    0.98 ## bbrier                                                 0.01 ## ppv                                                    0.98 ## npv                                                    1.00 ## specificity                                            0.99 ## sensitivity                                            0.99 ## prauc                                                  1.00 ##  ## [[3]] ##             pred_results_test$score(measures = mlr3::msrs(meas)) ## auc                                                         0.99 ## bacc                                                        0.97 ## mcc                                                         0.92 ## bbrier                                                      0.04 ## ppv                                                         0.93 ## npv                                                         0.99 ## specificity                                                 0.96 ## sensitivity                                                 0.97 ## prauc                                                       0.97"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-roc-curves-with-annotated-thresholds","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"ROC curves with annotated thresholds","title":"classification model interpretation using explainer package","text":"running next code chunk, get ROC Precision Recall curves development test sets time probability threshold information.","code":"ePerformance(task = maintask,          trained_model = mylrn,          splits = splits) ## [[1]] ##  ## [[2]] ##  ## [[3]]"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-loading-shap-results-for-downstream-analysis","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"loading SHAP results for downstream analysis","title":"classification model interpretation using explainer package","text":"Now can get outputs eSHAP_plot function apply clustering SHAP values","code":"shap_Mean_wide <- SHAP_output[[2]]  shap_Mean_long <- SHAP_output[[3]]  shap <- SHAP_output[[4]]"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-shap-values-in-association-with-feature-values","dir":"Articles","previous_headings":"Loading a dataset and training a machine learning model","what":"SHAP values in association with feature values","title":"classification model interpretation using explainer package","text":"","code":"ShapFeaturePlot(shap_Mean_long)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-partial-dependence-of-features","dir":"Articles","previous_headings":"","what":"partial dependence of features","title":"classification model interpretation using explainer package","text":"Partial dependence plots (PDPs): PDPs can used visualize marginal effect single feature model prediction.","code":"ShapPartialPlot(shap_Mean_long = shap_Mean_long)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-extract-feature-values-and-predicted-probabilities-as-output-of-the-model-to-analyze","dir":"Articles","previous_headings":"","what":"extract feature values and predicted probabilities as output of the model to analyze","title":"classification model interpretation using explainer package","text":"","code":"fval_predprob <- reshape2::dcast(shap, sample_num + pred_prob + predcorrectness ~ feature, value.var = \"feature.value\")"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-run-a-shiny-app-to-visualize-2-way-partial-dependence-plots","dir":"Articles","previous_headings":"","what":"Run a Shiny app to visualize 2-way partial dependence plots","title":"classification model interpretation using explainer package","text":"","code":"library(shiny) library(ggplot2) # assuming your data.table is named `fval_predprob` ui <- fluidPage(   titlePanel(\"Feature Plot\"),   sidebarLayout(     sidebarPanel(       selectInput(\"x_feature\", \"X-axis Feature:\",                   choices = names(fval_predprob)),       selectInput(\"y_feature\", \"Y-axis Feature:\",                   choices = names(fval_predprob)),       width = 2,       actionButton(\"stop_button\", \"Stop\")     ),     mainPanel(       plotOutput(\"feature_plot\")     )   ) )  server <- function(input, output) {      # create a reactive value for the app state   app_state <- reactiveValues(running = TRUE)      output$feature_plot <- renderPlot({     ggplot(fval_predprob, aes(x = .data[[input$x_feature]], y = .data[[input$y_feature]], fill = pred_prob)) +        geom_tile() +       scale_fill_gradient(low = \"white\", high = \"steelblue\", limits = c(0, 1)) +       xlab(input$x_feature) +       ylab(input$y_feature) +       labs(shape = \"correct prediction\") +       egg::theme_article()   })      # observe the stop button   observeEvent(input$stop_button, {     app_state$running <- FALSE   })      # stop the app if the running state is FALSE   observe({     if(!app_state$running) {       stopApp()     }   }) }  shinyApp(ui = ui, server = server) str(shap_Mean_long) ## tibble [1,980 x 9] (S3: tbl_df/tbl/data.frame) ##  $ feature           : chr [1:1980] \"Bare.nuclei\" \"Bare.nuclei\" \"Bare.nuclei\" \"Bare.nuclei\" ... ##  $ mean_phi          : num [1:1980] 0.0934 0.0934 0.0934 0.0934 0.0934 ... ##  $ Phi               : num [1:1980] -0.0859 -0.0821 -0.0317 0.0997 0.0817 ... ##  $ f_val             : num [1:1980] 0 0.111 0 0.444 0.556 ... ##  $ unscaled_f_val    : num [1:1980] 1 2 1 5 6 1 1 3 1 1 ... ##  $ sample_num        : int [1:1980] 1 2 3 4 5 6 7 8 9 10 ... ##  $ correct_prediction: Factor w/ 2 levels \"Incorrect\",\"Correct\": 2 2 2 1 2 2 2 2 2 2 ... ##  $ pred_prob         : num [1:1980] 0.00255 0.00182 0 0.92977 0.9283 ... ##  $ pred_class        : Factor w/ 2 levels \"malignant\",\"benign\": 2 2 2 1 1 2 2 1 2 2 ... # This is the data table that includes SHAP values in wide format. Each row contains sample_num as sample ID and the SHAP values for each feature. shap_Mean_wide ## Key: <sample_num> ##      sample_num Bare.nuclei  Bl.cromatin  Cell.shape   Cell.size Cl.thickness ##           <int>       <num>        <num>       <num>       <num>        <num> ##   1:          1 -0.08589487 -0.069985767 -0.04592299 -0.05557913 -0.016991720 ##   2:          2 -0.08207815 -0.043686534 -0.06930323 -0.07851767 -0.040950132 ##   3:          3 -0.03167399 -0.041501508 -0.05516873 -0.07578722 -0.026012011 ##   4:          4  0.09965638  0.100056508  0.16292108  0.13855823 -0.003343413 ##   5:          5  0.08170963  0.061670635  0.09991013  0.11153302 -0.024341667 ##  ---                                                                          ## 176:        176 -0.10101344 -0.022493651 -0.09723053 -0.11001489 -0.036337381 ## 177:        177 -0.07544257 -0.050335159 -0.07331122 -0.07960852 -0.052942063 ## 178:        178 -0.07287780 -0.023547804 -0.08396833 -0.07580437 -0.065089868 ## 179:        179 -0.12122407  0.054544259 -0.06030249 -0.03421050 -0.088212037 ## 180:        180  0.17650148  0.008577434  0.08656048  0.09603124  0.118961111 ##      Epith.c.size Marg.adhesion       Mitoses Normal.nucleoli           age ##             <num>         <num>         <num>           <num>         <num> ##   1: -0.027082751   0.002213201 -0.0022784127    -0.028862540 -0.0037774339 ##   2: -0.010480000  -0.018519815 -0.0023586243    -0.016425476 -0.0006488360 ##   3: -0.024506111  -0.020070503 -0.0010957672    -0.015432884 -0.0008956349 ##   4:  0.076623836   0.041688201 -0.0006521693     0.017386984  0.0067640741 ##   5:  0.038122116   0.030285079  0.0018288624     0.029264021 -0.0230379101 ##  ---                                                                        ## 176: -0.029844048  -0.031585979  0.0005687831    -0.027441481 -0.0015749206 ## 177: -0.024546667  -0.022700053 -0.0008221164    -0.020056270 -0.0021401058 ## 178: -0.020292487  -0.024337857 -0.0018688889    -0.019011217  0.0006503175 ## 179: -0.030457143  -0.004646905 -0.0040282540    -0.008570794  0.0014429101 ## 180: -0.006486825   0.047554444  0.0024593386     0.034816376 -0.0157181481 ##                sex ##              <num> ##   1:  0.0003026190 ##   2: -0.0004190476 ##   3:  0.0015755556 ##   4:  0.0008892857 ##   5:  0.0014779101 ##  ---               ## 176:  0.0011694974 ## 177: -0.0014722487 ## 178:  0.0008101587 ## 179: -0.0010852910 ## 180: -0.0008616667 # This is the data table of SHAP values in long format and includes feature name, mean_phi_test: mean shap value for the feature across samples, scaled feature values, shap values for each feature, sample ID, and whether the prediction was correct (i.e. predicted class = actual class) shap_Mean_long ## # A tibble: 1,980 x 9 ##    feature  mean_phi      Phi f_val unscaled_f_val sample_num correct_prediction ##    <chr>       <dbl>    <dbl> <dbl>          <dbl>      <int> <fct>              ##  1 Bare.nu~   0.0934 -0.0859  0                  1          1 Correct            ##  2 Bare.nu~   0.0934 -0.0821  0.111              2          2 Correct            ##  3 Bare.nu~   0.0934 -0.0317  0                  1          3 Correct            ##  4 Bare.nu~   0.0934  0.0997  0.444              5          4 Incorrect          ##  5 Bare.nu~   0.0934  0.0817  0.556              6          5 Correct            ##  6 Bare.nu~   0.0934 -0.0518  0                  1          6 Correct            ##  7 Bare.nu~   0.0934 -0.113   0                  1          7 Correct            ##  8 Bare.nu~   0.0934 -0.00175 0.222              3          8 Correct            ##  9 Bare.nu~   0.0934 -0.0468  0                  1          9 Correct            ## 10 Bare.nu~   0.0934 -0.221   0                  1         10 Correct            ## # i 1,970 more rows ## # i 2 more variables: pred_prob <dbl>, pred_class <fct>"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-patient-subgroups-determined-by-shap-clusters","dir":"Articles","previous_headings":"","what":"Patient subgroups determined by SHAP clusters","title":"classification model interpretation using explainer package","text":"SHAP clustering method better understand model may perform better patients others. example, can identify patient subgroups specific patterns different subgroups explains model developed perhaps better worse performance patients average performance whole dataset. can see difference SHAP plots group together provide overall SHAP summary plot. edges reflect features may interact individual sample (instance).","code":"# the number of clusters can be changed SHAP_plot_clusters <- SHAPclust(task = maintask,          trained_model = mylrn,          splits = splits,          shap_Mean_wide = shap_Mean_wide,          shap_Mean_long = shap_Mean_long,          num_of_clusters = 3,          seed = seed,          subset = .8) ## Key: <sample_num, feature, Phi> ##       sample_num         feature           Phi cluster    mean_phi     f_val ##            <int>          <char>         <num>   <int>       <num>     <num> ##    1:          1     Bare.nuclei -0.0858948677       3 0.093444244 0.0000000 ##    2:          1     Bl.cromatin -0.0699857672       3 0.044548987 0.0000000 ##    3:          1      Cell.shape -0.0459229894       3 0.076720237 0.0000000 ##    4:          1       Cell.size -0.0555791270       3 0.091198097 0.0000000 ##    5:          1    Cl.thickness -0.0169917196       3 0.069835393 0.5000000 ##   ---                                                                        ## 1976:        180   Marg.adhesion  0.0475544444       2 0.026453762 1.0000000 ## 1977:        180         Mitoses  0.0024593386       2 0.002165296 0.1250000 ## 1978:        180 Normal.nucleoli  0.0348163757       2 0.021391343 0.7777778 ## 1979:        180             age -0.0157181481       2 0.003230698 0.0000000 ## 1980:        180             sex -0.0008616667       2 0.001183048 0.0000000 ##       unscaled_f_val correct_prediction   pred_prob pred_class ##                <num>             <fctr>       <num>     <fctr> ##    1:              1            Correct 0.002554762     benign ##    2:              1            Correct 0.002554762     benign ##    3:              1            Correct 0.002554762     benign ##    4:              1            Correct 0.002554762     benign ##    5:              5            Correct 0.002554762     benign ##   ---                                                          ## 1976:             10            Correct 0.926616667  malignant ## 1977:              2            Correct 0.926616667  malignant ## 1978:              8            Correct 0.926616667  malignant ## 1979:             18            Correct 0.926616667  malignant ## 1980:              1            Correct 0.926616667  malignant ## Warning in geom_jitter(aes(shape = correct_prediction, text = paste(\"Feature: ## \", : Ignoring unknown aesthetics: text ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'ggimage' is ## missing. Will not plot arrows and zero-shading. ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'rsvg' is ## missing. Will not plot arrows and zero-shading. ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'ggimage' is ## missing. Will not plot arrows and zero-shading. ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'rsvg' is ## missing. Will not plot arrows and zero-shading. ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'ggimage' is ## missing. Will not plot arrows and zero-shading. ## Warning in cvms::plot_confusion_matrix(conf_matrix = cm_tbl): 'rsvg' is ## missing. Will not plot arrows and zero-shading. # note that the subset must be the same value as the SHAP analysis done earlier  # display the SHAP cluster plots SHAP_plot_clusters[[1]] # display the confusion matrices corresponding to the SHAP clusters (patient subsets determined by SHAP clusters) SHAP_plot_clusters[[2]]"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-model-fairness-sensitivity-analysis","dir":"Articles","previous_headings":"","what":"Model fairness (sensitivity analysis)","title":"classification model interpretation using explainer package","text":"Sometimes like investigate whether model performs fairly well different subgroups based categories variables sex.","code":"# you should decide what variables to use to be tested # here we chose sex from the variables existing in the dataset  Fairness_results <- eFairness(task = maintask,          trained_model = mylrn,          splits = splits,          target_variable = \"sex\",          var_levels = c(\"Male\", \"Female\")) ## Warning in verify_d(data$d): D not labeled 0/1, assuming benign = 0 and ## malignant = 1! ## Warning in verify_d(data$d): D not labeled 0/1, assuming benign = 0 and ## malignant = 1! ## Warning in verify_d(data$d): D not labeled 0/1, assuming benign = 0 and ## malignant = 1! # ROC curves for the subgroups for the development (left) and test (right) sets Fairness_results[[1]] # performance in the subgroups for the development set Fairness_results[[2]] ##             Male Female ## auc         1.00   1.00 ## bacc        0.99   0.99 ## mcc         0.97   0.98 ## bbrier      0.01   0.01 ## ppv         0.96   0.99 ## npv         1.00   0.99 ## specificity 0.98   0.99 ## sensitivity 1.00   0.99 ## prauc       1.00   1.00 # performance in the subgroups for the test set Fairness_results[[3]] ##             Male Female ## auc         0.98   0.99 ## bacc        0.98   0.96 ## mcc         0.94   0.91 ## bbrier      0.04   0.03 ## ppv         0.92   0.93 ## npv         1.00   0.97 ## specificity 0.96   0.96 ## sensitivity 1.00   0.95 ## prauc       0.96   0.98"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_binary_classification.html","id":"section-model-parameters","dir":"Articles","previous_headings":"Model fairness (sensitivity analysis)","what":"Model parameters","title":"classification model interpretation using explainer package","text":"","code":"# get model parameters model_params <- mylrn$param_set  print(data.table::as.data.table(model_params)) ##                               id    class lower upper ##                           <char>   <char> <num> <num> ##  1:       always.split.variables ParamUty    NA    NA ##  2:                class.weights ParamUty    NA    NA ##  3:                      holdout ParamLgl    NA    NA ##  4:                   importance ParamFct    NA    NA ##  5:                   keep.inbag ParamLgl    NA    NA ##  6:                    max.depth ParamInt     1   Inf ##  7:                   min.bucket ParamUty    NA    NA ##  8:                min.node.size ParamUty    NA    NA ##  9:                         mtry ParamInt     1   Inf ## 10:                   mtry.ratio ParamDbl     0     1 ## 11:                    na.action ParamFct    NA    NA ## 12:            num.random.splits ParamInt     1   Inf ## 13:                   node.stats ParamLgl    NA    NA ## 14:                  num.threads ParamInt     1   Inf ## 15:                    num.trees ParamInt     1   Inf ## 16:                    oob.error ParamLgl    NA    NA ## 17:        regularization.factor ParamUty    NA    NA ## 18:      regularization.usedepth ParamLgl    NA    NA ## 19:                      replace ParamLgl    NA    NA ## 20:    respect.unordered.factors ParamFct    NA    NA ## 21:              sample.fraction ParamDbl     0     1 ## 22:                  save.memory ParamLgl    NA    NA ## 23: scale.permutation.importance ParamLgl    NA    NA ## 24:                         seed ParamInt  -Inf   Inf ## 25:         split.select.weights ParamUty    NA    NA ## 26:                    splitrule ParamFct    NA    NA ## 27:                      verbose ParamLgl    NA    NA ## 28:                 write.forest ParamLgl    NA    NA ##                               id    class lower upper ##                                           levels nlevels is_bounded ##                                           <list>   <num>     <lgcl> ##  1:                                       [NULL]     Inf      FALSE ##  2:                                       [NULL]     Inf      FALSE ##  3:                                   TRUE,FALSE       2       TRUE ##  4: none,impurity,impurity_corrected,permutation       4       TRUE ##  5:                                   TRUE,FALSE       2       TRUE ##  6:                                       [NULL]     Inf      FALSE ##  7:                                       [NULL]     Inf      FALSE ##  8:                                       [NULL]     Inf      FALSE ##  9:                                       [NULL]     Inf      FALSE ## 10:                                       [NULL]     Inf       TRUE ## 11:                     na.learn,na.omit,na.fail       3       TRUE ## 12:                                       [NULL]     Inf      FALSE ## 13:                                   TRUE,FALSE       2       TRUE ## 14:                                       [NULL]     Inf      FALSE ## 15:                                       [NULL]     Inf      FALSE ## 16:                                   TRUE,FALSE       2       TRUE ## 17:                                       [NULL]     Inf      FALSE ## 18:                                   TRUE,FALSE       2       TRUE ## 19:                                   TRUE,FALSE       2       TRUE ## 20:                       ignore,order,partition       3       TRUE ## 21:                                       [NULL]     Inf       TRUE ## 22:                                   TRUE,FALSE       2       TRUE ## 23:                                   TRUE,FALSE       2       TRUE ## 24:                                       [NULL]     Inf      FALSE ## 25:                                       [NULL]     Inf      FALSE ## 26:                    gini,extratrees,hellinger       3       TRUE ## 27:                                   TRUE,FALSE       2       TRUE ## 28:                                   TRUE,FALSE       2       TRUE ##                                           levels nlevels is_bounded ##     special_vals        default storage_type                   tags ##           <list>         <list>       <char>                 <list> ##  1:    <list[0]> <NoDefault[0]>         list                  train ##  2:    <list[0]>         [NULL]         list                  train ##  3:    <list[0]>          FALSE      logical                  train ##  4:    <list[0]> <NoDefault[0]>    character                  train ##  5:    <list[0]>          FALSE      logical                  train ##  6:    <list[1]>         [NULL]      integer                  train ##  7:    <list[0]>              1         list                  train ##  8:    <list[1]>         [NULL]         list                  train ##  9:    <list[1]> <NoDefault[0]>      integer                  train ## 10:    <list[0]> <NoDefault[0]>      numeric                  train ## 11:    <list[0]>       na.learn    character                  train ## 12:    <list[0]>              1      integer                  train ## 13:    <list[0]>          FALSE      logical                  train ## 14:    <list[0]>              1      integer  train,predict,threads ## 15:    <list[0]>            500      integer train,predict,hotstart ## 16:    <list[0]>           TRUE      logical                  train ## 17:    <list[0]>              1         list                  train ## 18:    <list[0]>          FALSE      logical                  train ## 19:    <list[0]>           TRUE      logical                  train ## 20:    <list[0]> <NoDefault[0]>    character                  train ## 21:    <list[0]> <NoDefault[0]>      numeric                  train ## 22:    <list[0]>          FALSE      logical                  train ## 23:    <list[0]>          FALSE      logical                  train ## 24:    <list[1]>         [NULL]      integer          train,predict ## 25:    <list[0]>         [NULL]         list                  train ## 26:    <list[0]>           gini    character                  train ## 27:    <list[0]>           TRUE      logical          train,predict ## 28:    <list[0]>           TRUE      logical                  train ##     special_vals        default storage_type                   tags"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"load-required-libraries","dir":"Articles","previous_headings":"","what":"Load Required Libraries","title":"SHAP analysis in multi-class classification tasks","text":"begin loading necessary packages.","code":"library(explainer) library(mlbench) library(mlr3learners) ## Loading required package: mlr3 library(ranger) library(iml) library(dplyr) ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(ggplot2) library(plotly) ##  ## Attaching package: 'plotly' ## The following object is masked from 'package:ggplot2': ##  ##     last_plot ## The following object is masked from 'package:stats': ##  ##     filter ## The following object is masked from 'package:graphics': ##  ##     layout library(cvms) library(ggplot2) library(gridExtra) ##  ## Attaching package: 'gridExtra' ## The following object is masked from 'package:dplyr': ##  ##     combine"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"set-seed-for-reproducibility","dir":"Articles","previous_headings":"","what":"Set Seed for Reproducibility","title":"SHAP analysis in multi-class classification tasks","text":"","code":"seed <- 246 set.seed(seed)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"load-and-prepare-the-data","dir":"Articles","previous_headings":"","what":"Load and Prepare the Data","title":"SHAP analysis in multi-class classification tasks","text":"use Iris dataset example define target column (Species).","code":"# Load the Iris dataset data(\"iris\") target_col <- \"Species\"  # Extract relevant columns from the dataset mydata <- iris"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"create-the-classification-task","dir":"Articles","previous_headings":"","what":"Create the Classification Task","title":"SHAP analysis in multi-class classification tasks","text":"create classification task using mlr3 package.","code":"maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col )"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"split-the-dataset","dir":"Articles","previous_headings":"","what":"Split the Dataset","title":"SHAP analysis in multi-class classification tasks","text":"split data training test sets.","code":"splits <- mlr3::partition(maintask, ratio = 0.3)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"train-the-model","dir":"Articles","previous_headings":"","what":"Train the Model","title":"SHAP analysis in multi-class classification tasks","text":"Using ranger algorithm, train classification model.","code":"mylrn <- mlr3::lrn(\"classif.ranger\", predict_type = \"prob\") mylrn$train(maintask, splits$train)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"make-predictions","dir":"Articles","previous_headings":"","what":"Make Predictions","title":"SHAP analysis in multi-class classification tasks","text":"model trained, make predictions test set.","code":"# Make predictions on the test set predictions <- mylrn$predict(maintask, splits$test)  # Convert predictions to a data frame predicted_classes <- predictions$response true_classes <- mydata[splits$test, target_col]"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"confusion-matrix","dir":"Articles","previous_headings":"","what":"Confusion Matrix","title":"SHAP analysis in multi-class classification tasks","text":"create visualize confusion matrix using cvms package.","code":"# Create a confusion matrix conf_matrix <- table(True = true_classes, Predicted = predicted_classes)  # Convert the confusion matrix to a data frame with required column names conf_matrix_df <- as.data.frame(conf_matrix) colnames(conf_matrix_df) <- c(\"Target\", \"Prediction\", \"N\")  # Plot the confusion matrix plot_confusion_matrix(conf_matrix_df) ## Warning in plot_confusion_matrix(conf_matrix_df): 'ggimage' is missing. Will ## not plot arrows and zero-shading. ## Warning in plot_confusion_matrix(conf_matrix_df): 'rsvg' is missing. Will not ## plot arrows and zero-shading."},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"shap-shapley-additive-explanations-analysis","dir":"Articles","previous_headings":"","what":"SHAP (SHapley Additive exPlanations) Analysis","title":"SHAP analysis in multi-class classification tasks","text":"now compute SHAP values dataset understand feature importance class. now use SHAP function generate SHAP plots class combined plot classes.","code":"SHAP_output <- eSHAP_plot_multiclass(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 30,   seed = seed,   subset = 0.8 ) # Display the combined SHAP plot for each class print(SHAP_output$combined_plot) ## TableGrob (3 x 1) \"arrange\": 3 grobs ##            z     cells    name           grob ## setosa     1 (1-1,1-1) arrange gtable[layout] ## versicolor 2 (2-2,1-1) arrange gtable[layout] ## virginica  3 (3-3,1-1) arrange gtable[layout]"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"display-the-combined-plot-for-all-classes-together","dir":"Articles","previous_headings":"","what":"Display the combined plot for all classes together","title":"SHAP analysis in multi-class classification tasks","text":"","code":"print(SHAP_output$combined_all_classes)"},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_multiclass.html","id":"notes","dir":"Articles","previous_headings":"Display the combined plot for all classes together","what":"Notes:","title":"SHAP analysis in multi-class classification tasks","text":"script loads Iris dataset, trains classifier using ranger algorithm, makes predictions, creates confusion matrix, calculates SHAP values feature importance. SHAP values visualized per class across classes using ggplot2.","code":""},{"path":"https://persimune.github.io/explainer/articles/explainer_tutorial_regression.html","id":"regression-model-evaluation","dir":"Articles","previous_headings":"","what":"regression model evaluation","title":"regression model interpretation using explainer package","text":"Mean Squared Error (MSE): Measures average squared differences predicted actual values. Smaller MSE values indicate better model performance, sensitive outliers. Root Mean Squared Error (RMSE): square root MSE, providing measure average absolute errors. Lower RMSE values signify better model accuracy. Mean Absolute Error (MAE): Calculates average absolute differences predicted actual values. MAE less sensitive outliers MSE RMSE. R-squared (R²): Represents proportion variance target variable model explains. R² ranges 0 1, higher values indicate better fit data. evaluating regression model, aim minimize MSE, RMSE, MAE maximizing R-squared achieve accurate precise predictions. combination metrics provides comprehensive assessment model’s performance suitability given task.","code":"# Regression model evaluation regressmdl_eval_results <- regressmdl_eval(task = maintask,            trained_model = mylrn,            splits = splits)  # display the results regressmdl_eval_results ##        MSE     RMSE      MAE R_squared ## 1 4.393614 2.096095 1.777186 0.4177224"},{"path":"https://persimune.github.io/explainer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ramtin Zargari Marandi. Author, maintainer.","code":""},{"path":"https://persimune.github.io/explainer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zargari Marandi, R. (2024). ExplaineR: R package explain machine learning models. Bioinformatics advances, 4(1), p. vbae049. doi:10.1093/bioadv/vbae049. https://doi.org/10.1093/bioadv/vbae049","code":"@Article{,   title = {ExplaineR: an R package to explain machine learning models},   author = {{R. Zargari Marandi}},   journal = {Bioinformatics advances},   year = {2024},   volume = {4},   number = {1},   pages = {vbae049},   doi = {10.1093/bioadv/vbae049},   howpublished = {https://doi.org/10.1093/bioadv/vbae049}, }"},{"path":[]},{"path":"https://persimune.github.io/explainer/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Machine Learning Model Explainer","text":"enables detailed interpretation complex classification regression models Shapley analysis including data-driven characterization subgroups individuals. Furthermore, facilitates multi-measure model evaluation, model fairness, decision curve analysis. Additionally, offers enhanced visualizations interactive elements. Find use package checking package tutorials.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Machine Learning Model Explainer","text":"can install released version package CRAN: development version GitHub:","code":"install.packages(\"explainer\") # install.packages(\"devtools\") devtools::install_github(\"PERSIMUNE/explainer\")"},{"path":"https://persimune.github.io/explainer/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Machine Learning Model Explainer","text":"short example use package. See articles examples.","code":"# Load necessary packages library(\"explainer\")  # Set seed for reproducibility seed <- 246 set.seed(seed)  # load necessary packages library(mlbench) library(mlr3learners) library(ranger)  # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\")  # Specify target column and positive class target_col <- \"Class\" positive_class <- \"malignant\"  # Extract relevant columns from dataset mydata <- BreastCancer[, -1] mydata <- na.omit(mydata)  # Generate random 'sex' and 'age' columns sex <- sample(c(\"Male\", \"Female\"), size = nrow(mydata), replace = TRUE) mydata$age <- as.numeric(sample(seq(18, 60), size = nrow(mydata), replace = TRUE)) mydata$sex <- factor(sex, levels = c(\"Male\", \"Female\"), labels = c(1, 0))  # Create a classification task maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class )  # Split the dataset for training splits <- mlr3::partition(maintask)  # Create a ranger learner for classification mylrn <- mlr3::lrn(\"classif.ranger\", predict_type = \"prob\")  # Train the learner on the training set mylrn$train(maintask, splits$train)  # Generate SHAP values and plot SHAP_output <- eSHAP_plot(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 30,   seed = seed,   subset = 0.8 )  shap_Mean_wide <- SHAP_output[[2]]  shap_Mean_long <- SHAP_output[[3]]  # Generate SHAP clusters and plot SHAP_plot_clusters <- SHAPclust(   task = maintask,   trained_model = mylrn,   splits = splits,   shap_Mean_wide = shap_Mean_wide,   shap_Mean_long = shap_Mean_long,   num_of_clusters = 3,   seed = seed,   subset = 0.8 )  # Please note that the colors on the legend on SHAP cluster plot is not the same as in the SHAP summary plot, but the markers are the same. # The markers indicate prediction correctness not the colors (so the colors could be manually changed to black/white on the legend when reporting)"},{"path":"https://persimune.github.io/explainer/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Machine Learning Model Explainer","text":"Official Documentation","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Machine Learning Model Explainer","text":"use package research, please consider citing : Zargari Marandi, Ramtin. “ExplaineR: R package explain machine learning models.” Bioinformatics Advances 4, . 1 (2024): vbae049.doi:10.1093/bioadv/vbae049","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Machine Learning Model Explainer","text":"want contribute development package, please read CONTRIBUTING.md guidelines.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Machine Learning Model Explainer","text":"encounter issues suggestions, please open issue.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"major-updates","dir":"","previous_headings":"","what":"Major updates","title":"Machine Learning Model Explainer","text":"23-09-2024: new function multi-class classification added, check tutorial multi-class classification use function (eSHAP_plot_multiclass.R).","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Machine Learning Model Explainer","text":"package released MIT License.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Machine Learning Model Explainer","text":"Zargari Marandi R, Leung P, Sigera C, Murray DD, Weeratunga P, Fernando D, Rodrigo C, Rajapakse S, MacPherson CR, (2023). Development machine learning model early prediction plasma leakage suspected dengue patients. PLoS Negl Trop Dis 17(3): e0010758. doi:10.1371/journal.pntd.0010758 Lang M, Binder M, Richter J, Schratz P, Pfisterer F, Coors S, Au Q, Casalicchio G, Kotthoff L, Bischl B, (2019). mlr3: modern object-oriented machine learning framework R. Journal Open Source Software. doi:10.21105/joss.01903 Molnar C, Bischl B, Casalicchio G, (2018). iml: R package Interpretable Machine Learning.JOSS, 3(26), 786. doi:10.21105/joss.00786 Lundberg SM Lee SI, (2017). unified approach interpreting model predictions. Advances neural information processing systems.arXiv:1705.07874 Ludvig Renbo Olsen Hugh Benjamin Zachariae, (2022). cvms: Cross-Validation Model Selection. R package version 1.3.4. https://CRAN.R-project.org/package=cvms R Core Team (2021). R: language environment statistical computing. R Foundation Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Machine Learning Model Explainer","text":"Many thanks colleagues CHIP/PERSIMUNE support work feedback. addition, thanks CRAN team well authors maintainers utilized packages dedication advancing R ecosystem.","code":""},{"path":"https://persimune.github.io/explainer/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"Machine Learning Model Explainer","text":"work supported Danish National Research Foundation (DNRF126).","code":""},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":null,"dir":"Reference","previous_headings":"","what":"SHAP clustering — SHAPclust","title":"SHAP clustering — SHAPclust","text":"SHAP values used cluster data samples using k-means method identify subgroups individuals specific patterns feature contributions.","code":""},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SHAP clustering — SHAPclust","text":"","code":"SHAPclust(   task,   trained_model,   splits,   shap_Mean_wide,   shap_Mean_long,   num_of_clusters = 4,   seed = 246,   subset = 1,   algorithm = \"Hartigan-Wong\",   iter.max = 1000 )"},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SHAP clustering — SHAPclust","text":"task mlr3 task binary classification trained_model mlr3 trained learner object splits mlr3 object defining data splits train test sets shap_Mean_wide data frame SHAP values wide format eSHAP_plot.R shap_Mean_long data frame SHAP values long format eSHAP_plot.R num_of_clusters number clusters make based SHAP values, default: 4 seed integer reproducibility, Default 246 subset percentage instances use 0 1 1 means algorithm k-means algorithm character: \"Hartigan-Wong\", \"Lloyd\", \"Forgy\", \"MacQueen\". iter.max maximum number iterations allowed","code":""},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SHAP clustering — SHAPclust","text":"list containing four elements: shap_plot_onerow interactive plot displaying SHAP values feature, clustered specified number clusters. cluster shown facet. combined_plot ggplot2 figure combining confusion matrices cluster, providing insights model's performance within identified subgroup. kmeans_fvals_desc summary table containing statistical descriptions clusters based feature values. shap_Mean_wide_kmeans data frame containing clustered SHAP values along predictions ground truth information. kmeans_info Information k-means clustering process, including cluster centers assignment details.","code":""},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SHAP clustering — SHAPclust","text":"Zargari Marandi, R., 2024. ExplaineR: R package explain machine learning models. Bioinformatics advances, 4(1), p.vbae049, https://doi.org/10.1093/bioadv/vbae049.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/SHAPclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SHAP clustering — SHAPclust","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) SHAP_output <- eSHAP_plot(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 2, # also 30 or more   seed = seed,   subset = 0.02 # up to 1 ) #> Error in ungroup(.): could not find function \"ungroup\" shap_Mean_wide <- SHAP_output[[2]] #> Error: object 'SHAP_output' not found shap_Mean_long <- SHAP_output[[3]] #> Error: object 'SHAP_output' not found SHAP_plot_clusters <- SHAPclust(   task = maintask,   trained_model = mylrn,   splits = splits,   shap_Mean_wide = shap_Mean_wide,   shap_Mean_long = shap_Mean_long,   num_of_clusters = 3, # your choice   seed = seed,   subset = 0.02, # match with eSHAP_plot   algorithm = \"Hartigan-Wong\",   iter.max = 10 ) #> Error: object 'shap_Mean_wide' not found # }"},{"path":"https://persimune.github.io/explainer/reference/ShapFeaturePlot.html","id":null,"dir":"Reference","previous_headings":"","what":"SHAP Values versus Feature Values — ShapFeaturePlot","title":"SHAP Values versus Feature Values — ShapFeaturePlot","text":"SHAP values association feature values","code":""},{"path":"https://persimune.github.io/explainer/reference/ShapFeaturePlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SHAP Values versus Feature Values — ShapFeaturePlot","text":"","code":"ShapFeaturePlot(shap_Mean_long)"},{"path":"https://persimune.github.io/explainer/reference/ShapFeaturePlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SHAP Values versus Feature Values — ShapFeaturePlot","text":"shap_Mean_long data frame containing SHAP values long format","code":""},{"path":"https://persimune.github.io/explainer/reference/ShapFeaturePlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SHAP Values versus Feature Values — ShapFeaturePlot","text":"interactive plot SHAP values association feature values","code":""},{"path":"https://persimune.github.io/explainer/reference/ShapFeaturePlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SHAP Values versus Feature Values — ShapFeaturePlot","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) SHAP_output <- eSHAP_plot(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 2, # also 30 or more   seed = seed,   subset = 0.02 # up to 1 ) #> Error in ungroup(.): could not find function \"ungroup\" shap_Mean_long <- SHAP_output[[3]] #> Error: object 'SHAP_output' not found myplot <- ShapFeaturePlot(shap_Mean_long) #> Error: object 'shap_Mean_long' not found # }"},{"path":"https://persimune.github.io/explainer/reference/eCM_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced Confusion Matrix Plot — eCM_plot","title":"Enhanced Confusion Matrix Plot — eCM_plot","text":"function generates enhanced confusion matrix plot using CVMS package. plot includes visualizations sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV).","code":""},{"path":"https://persimune.github.io/explainer/reference/eCM_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced Confusion Matrix Plot — eCM_plot","text":"","code":"eCM_plot(task, trained_model, splits, add_sums = TRUE, palette = \"Green\")"},{"path":"https://persimune.github.io/explainer/reference/eCM_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced Confusion Matrix Plot — eCM_plot","text":"task mlr3 task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets add_sums logical, indicating whether total numbers displayed plot (default: TRUE) palette character, color palette confusion matrix (default: \"Green\")","code":""},{"path":"https://persimune.github.io/explainer/reference/eCM_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced Confusion Matrix Plot — eCM_plot","text":"confusion matrix plot visualizing sensitivity, specificity, PPV, NPV","code":""},{"path":"https://persimune.github.io/explainer/reference/eCM_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced Confusion Matrix Plot — eCM_plot","text":"","code":"library(\"explainer\") seed <- 246 set.seed(seed)  # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) myplot <- eCM_plot(   task = maintask,   trained_model = mylrn,   splits = splits ) #> Warning: 'ggimage' is missing. Will not plot arrows and zero-shading. #> Warning: 'rsvg' is missing. Will not plot arrows and zero-shading. #> Warning: 'ggnewscale' is missing. Will not use palette for sum tiles. #> Warning: 'ggimage' is missing. Will not plot arrows and zero-shading. #> Warning: 'rsvg' is missing. Will not plot arrows and zero-shading. #> Warning: 'ggnewscale' is missing. Will not use palette for sum tiles."},{"path":"https://persimune.github.io/explainer/reference/eDecisionCurve.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision Curve Plot — eDecisionCurve","title":"Decision Curve Plot — eDecisionCurve","text":"Decision curve analysis statistical method used medical research evaluate compare clinical utility different diagnostic predictive models. assesses net benefit model across range decision thresholds, aiding selection informative practical approach guiding clinical decisions.","code":""},{"path":"https://persimune.github.io/explainer/reference/eDecisionCurve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decision Curve Plot — eDecisionCurve","text":"","code":"eDecisionCurve(task, trained_model, splits, seed = 246)"},{"path":"https://persimune.github.io/explainer/reference/eDecisionCurve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decision Curve Plot — eDecisionCurve","text":"task mlr3 task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets seed numeric, seed reproducibility (default: 246)","code":""},{"path":"https://persimune.github.io/explainer/reference/eDecisionCurve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decision Curve Plot — eDecisionCurve","text":"interactive decision curve plot","code":""},{"path":"https://persimune.github.io/explainer/reference/eDecisionCurve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decision Curve Plot — eDecisionCurve","text":"","code":"library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) myplot <- eDecisionCurve(   task = maintask,   trained_model = mylrn,   splits = splits,   seed = seed )"},{"path":"https://persimune.github.io/explainer/reference/eFairness.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced Fairness Analysis — eFairness","title":"Enhanced Fairness Analysis — eFairness","text":"function generates Precision-Recall ROC curves sample subgroups, facilitating fairness analysis binary classification model.","code":""},{"path":"https://persimune.github.io/explainer/reference/eFairness.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced Fairness Analysis — eFairness","text":"","code":"eFairness(task, trained_model, splits, target_variable, var_levels)"},{"path":"https://persimune.github.io/explainer/reference/eFairness.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced Fairness Analysis — eFairness","text":"task mlr3 binary classification task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets target_variable character, variable dataset used test model's performance var_levels list, defining levels specified variable","code":""},{"path":"https://persimune.github.io/explainer/reference/eFairness.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced Fairness Analysis — eFairness","text":"Model performance metrics user-specified subgroups using Precision-Recall ROC curves","code":""},{"path":"https://persimune.github.io/explainer/reference/eFairness.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced Fairness Analysis — eFairness","text":"","code":"library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) # sex is chosen for fairness analysis Fairness_results <- eFairness(   task = maintask,   trained_model = mylrn,   splits = splits,   target_variable = \"sex\",   var_levels = c(\"Male\", \"Female\") ) #> Warning: D not labeled 0/1, assuming benign = 0 and malignant = 1! #> Warning: D not labeled 0/1, assuming benign = 0 and malignant = 1! #> Warning: D not labeled 0/1, assuming benign = 0 and malignant = 1!"},{"path":"https://persimune.github.io/explainer/reference/eROC_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced ROC and Precision-Recall Plots — eROC_plot","title":"Enhanced ROC and Precision-Recall Plots — eROC_plot","text":"function generates Precision-Recall ROC curves binary classification models.","code":""},{"path":"https://persimune.github.io/explainer/reference/eROC_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced ROC and Precision-Recall Plots — eROC_plot","text":"","code":"eROC_plot(task, trained_model, splits)"},{"path":"https://persimune.github.io/explainer/reference/eROC_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced ROC and Precision-Recall Plots — eROC_plot","text":"task mlr3 binary classification task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets","code":""},{"path":"https://persimune.github.io/explainer/reference/eROC_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced ROC and Precision-Recall Plots — eROC_plot","text":"ROC Precision-Recall curves","code":""},{"path":"https://persimune.github.io/explainer/reference/eROC_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced ROC and Precision-Recall Plots — eROC_plot","text":"","code":"library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) myplot <- eROC_plot(   task = maintask,   trained_model = mylrn,   splits = splits )"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"SHAP plot classification models visualization tool uses Shapley value, approach cooperative game theory, compute feature contributions single predictions. Shapley value fairly distributes difference instance’s prediction datasets average prediction among features. method available iml package.","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"","code":"eSHAP_plot(   task,   trained_model,   splits,   sample.size = 30,   seed = 246,   subset = 1 )"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"task mlr3 task object binary classification trained_model mlr3 trained learner object splits mlr3 object defining data splits train test sets sample.size numeric, default 30. larger value, slower accurate estimate SHAP values seed numeric, integer reproducibility. Default 246 subset numeric, percentage instances use 0 1 1 means ","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"list containing: shap_plot enhanced SHAP plot user interactive elements. shap_Mean_wide matrix SHAP values. shap_Mean data.table aggregated SHAP values. shap Raw SHAP values. shap_pred_plot plot depicting SHAP values versus predicted probabilities.","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"Zargari Marandi, R., 2024. ExplaineR: R package explain machine learning models. Bioinformatics advances, 4(1), p.vbae049. Molnar C, Casalicchio G, Bischl B. iml: R package interpretable machine learning. Journal Open Source Software. 2018 Jun 27;3(26):786.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced SHAP Analysis for Binary Classification Models — eSHAP_plot","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(c(\"Male\", \"Female\"), size = nrow(mydata), replace = TRUE) mydata$age <- as.numeric(sample(seq(18, 60), size = nrow(mydata), replace = TRUE)) mydata$sex <- factor(sex, levels = c(\"Male\", \"Female\"), labels = c(1, 0)) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(\"classif.ranger\", predict_type = \"prob\") mylrn$train(maintask, splits$train) SHAP_output <- eSHAP_plot(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 2, # also 30 or more   seed = seed,   subset = 0.02 # up to 1 ) #> Error in ungroup(.): could not find function \"ungroup\" # }"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_multiclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","title":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","text":"SHAP plot multi-class classification models visualization tool uses Shapley value compute feature contributions single predictions across multiple classes.","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_multiclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","text":"","code":"eSHAP_plot_multiclass(   task,   trained_model,   splits,   sample.size = 30,   seed = 246,   subset = 1 )"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_multiclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","text":"task mlr3 task object multi-class classification trained_model mlr3 trained learner object splits mlr3 object defining data splits train test sets sample.size numeric, default 30. larger value, slower accurate estimate SHAP values seed numeric, integer reproducibility. Default 246 subset numeric, percentage instances use 0 1 1 means ","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_multiclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","text":"list containing: combined_plots SHAP plot depicting SHAP values class shap_data matrix SHAP values class. combined_all_classes overall SHAP plot depicting SHAP values classes single plot","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_multiclass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced SHAP Analysis for Multi-Class Classification Models — eSHAP_plot_multiclass","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages and data... # }"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_reg.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","title":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","text":"SHAP plot regression models visualization tool uses Shapley value, approach cooperative game theory, compute feature contributions single predictions. Shapley value fairly distributes difference instance’s prediction datasets average prediction among features. method available iml package.","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_reg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","text":"","code":"eSHAP_plot_reg(   task,   trained_model,   splits,   sample.size = 30,   seed = 246,   subset = 1 )"},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_reg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","text":"task mlr3 regression task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets sample.size numeric, number samples calculate SHAP values (default: 30) seed numeric, seed reproducibility (default: 246) subset numeric, proportion test set use visualization (default: 1)","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_reg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","text":"list two objects: enhanced SHAP plot user interactive elements, matrix SHAP values","code":""},{"path":"https://persimune.github.io/explainer/reference/eSHAP_plot_reg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced SHAP Analysis for Regression Models — eSHAP_plot_reg","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(c(\"Male\", \"Female\"), size = nrow(mydata), replace = TRUE) mydata$age <- sample(seq(18, 60), size = nrow(mydata), replace = TRUE) mydata$sex <- factor(sex, levels = c(\"Male\", \"Female\"), labels = c(1, 0)) mydata$Class <- NULL mydata$Cl.thickness <- as.numeric(mydata$Cl.thickness) target_col <- \"Cl.thickness\" maintask <- mlr3::TaskRegr$new(   id = \"my_regression_task\",   backend = mydata,   target = target_col ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(\"regr.ranger\", predict_type = \"response\") mylrn$train(maintask, splits$train) reg_model_outputs <- mylrn$predict(maintask, splits$test) SHAP_output <- eSHAP_plot_reg(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 2, # also 30 or more   seed = seed,   subset = 0.02 # up to 1 ) #> Warning: Ignoring unknown aesthetics: text myplot <- SHAP_output[[1]] # }"},{"path":"https://persimune.github.io/explainer/reference/eperformance.html","id":null,"dir":"Reference","previous_headings":"","what":"Enhanced Performance Evaluation — ePerformance","title":"Enhanced Performance Evaluation — ePerformance","text":"function generates Precision-Recall ROC curves, including threshold information binary classification models.","code":""},{"path":"https://persimune.github.io/explainer/reference/eperformance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Enhanced Performance Evaluation — ePerformance","text":"","code":"ePerformance(task, trained_model, splits)"},{"path":"https://persimune.github.io/explainer/reference/eperformance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Enhanced Performance Evaluation — ePerformance","text":"task mlr3 binary classification task object specifying task details trained_model mlr3 trained learner (model) object obtained training splits mlr3 object defining data splits train test sets","code":""},{"path":"https://persimune.github.io/explainer/reference/eperformance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Enhanced Performance Evaluation — ePerformance","text":"ROC Precision-Recall curves threshold information","code":""},{"path":"https://persimune.github.io/explainer/reference/eperformance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Enhanced Performance Evaluation — ePerformance","text":"","code":"# Set environment variables for reproducibility Sys.setenv(LANG = \"en\") # Change R language to English! RNGkind(\"L'Ecuyer-CMRG\") # Change to L'Ecuyer-CMRG instead of the default \"Mersenne-Twister\"  # Load required libraries library(\"explainer\")  # Set seed for reproducibility seed <- 246 set.seed(seed)  # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\")  # Keep the target column as \"Class\" target_col <- \"Class\"  # Change the positive class to \"malignant\" positive_class <- \"malignant\"  # Keep only the predictor variables and outcome mydata <- BreastCancer[, -1] # 1 is ID  # Remove rows with missing values mydata <- na.omit(mydata)  # Create a vector of sex categories sex <- sample(c(\"Male\", \"Female\"), size = nrow(mydata), replace = TRUE)  # Create a vector of age categories mydata$age <- as.numeric(sample(seq(18, 60), size = nrow(mydata), replace = TRUE))  # Add a sex column to the mydata data frame (for fairness analysis) mydata$sex <- factor(sex, levels = c(\"Male\", \"Female\"), labels = c(1, 0))  # Create a classification task maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class )  # Create a train-test split set.seed(seed) splits <- mlr3::partition(maintask)  # Add a learner (machine learning model base) # Here we use random forest for example (you can use any other available model) mylrn <- mlr3::lrn(\"classif.ranger\", predict_type = \"prob\")  # Train the model mylrn$train(maintask, splits$train)  # Make predictions on new data mylrn$predict(maintask, splits$test) #>  #> ── <PredictionClassif> for 225 observations: ─────────────────────────────────── #>  row_ids     truth  response prob.malignant prob.benign #>        2    benign malignant     0.86798175  0.13201825 #>        5    benign    benign     0.00922619  0.99077381 #>        7    benign    benign     0.35852381  0.64147619 #>      ---       ---       ---            ---         --- #>      671    benign    benign     0.00000000  1.00000000 #>      675    benign    benign     0.00230000  0.99770000 #>      681 malignant malignant     0.91511905  0.08488095 ePerformance(task = maintask, trained_model = mylrn, splits = splits) #> [[1]]  #>  #> [[2]] #>  #> [[3]] #>"},{"path":"https://persimune.github.io/explainer/reference/explainer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"explainer: Machine Learning Model Explainer — explainer-package","title":"explainer: Machine Learning Model Explainer — explainer-package","text":"enables detailed interpretation complex classification regression models Shapley analysis including data-driven characterization subgroups individuals. Furthermore, facilitates multi-measure model evaluation, model fairness, decision curve analysis. Additionally, offers enhanced visualizations interactive elements.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/explainer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"explainer: Machine Learning Model Explainer — explainer-package","text":"Maintainer: Ramtin Zargari Marandi ramtin.zargari.marandi@regionh.dk (ORCID)","code":""},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":null,"dir":"Reference","previous_headings":"","what":"Data scale to 0 and 1 — range01","title":"Data scale to 0 and 1 — range01","text":"Scale data range 0 1. uses Hampel filter adjust outliers, followed min-max normalization.","code":""},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data scale to 0 and 1 — range01","text":"","code":"range01(x)"},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data scale to 0 and 1 — range01","text":"x Vector array numbers normalized","code":""},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data scale to 0 and 1 — range01","text":"Normalized vector","code":""},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data scale to 0 and 1 — range01","text":"Pearson, R. K. (1999). “Data cleaning dynamic modeling control”. European Control Conference, ETH Zurich, Switzerland.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/range01.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data scale to 0 and 1 — range01","text":"","code":"normalized_vector <- range01(seq(-10:1000))"},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":null,"dir":"Reference","previous_headings":"","what":"Regression Model Evaluation — regressmdl_eval","title":"Regression Model Evaluation — regressmdl_eval","text":"Provides calculations measures evaluate regression models.","code":""},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regression Model Evaluation — regressmdl_eval","text":"","code":"regressmdl_eval(task, trained_model, splits)"},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regression Model Evaluation — regressmdl_eval","text":"task mlr3 regression task object trained_model mlr3 trained learner (model) object splits mlr3 object defining data splits train test sets","code":""},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regression Model Evaluation — regressmdl_eval","text":"Data frame containing regression evaluation measures","code":""},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Regression Model Evaluation — regressmdl_eval","text":"Lang M, Binder M, Richter J, Schratz P, Pfisterer F, Coors S, Au Q, Casalicchio G, Kotthoff L, Bischl B. mlr3: modern object-oriented machine learning framework R. Journal Open Source Software. 2019 Dec 11;4(44):1903.","code":""},{"path":[]},{"path":"https://persimune.github.io/explainer/reference/regressmdl_eval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regression Model Evaluation — regressmdl_eval","text":"","code":"library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE ) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) mydata$Class <- NULL mydata$Cl.thickness <- as.numeric(mydata$Cl.thickness) target_col <- \"Cl.thickness\" maintask <- mlr3::TaskRegr$new(   id = \"my_regression_task\",   backend = mydata,   target = target_col ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"regr.ranger\",   predict_type = \"response\" ) mylrn$train(maintask, splits$train) regressmdl_eval_results <- regressmdl_eval(   task = maintask,   trained_model = mylrn,   splits = splits )"},{"path":"https://persimune.github.io/explainer/reference/shapPartialPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"SHAP Partial Plot — ShapPartialPlot","title":"SHAP Partial Plot — ShapPartialPlot","text":"Generates interactive partial dependence plot based SHAP values, visualizing marginal effect one two features predicted outcome machine learning model.","code":""},{"path":"https://persimune.github.io/explainer/reference/shapPartialPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SHAP Partial Plot — ShapPartialPlot","text":"","code":"ShapPartialPlot(shap_Mean_long)"},{"path":"https://persimune.github.io/explainer/reference/shapPartialPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SHAP Partial Plot — ShapPartialPlot","text":"shap_Mean_long data frame containing SHAP values long format","code":""},{"path":"https://persimune.github.io/explainer/reference/shapPartialPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SHAP Partial Plot — ShapPartialPlot","text":"interactive partial dependence plot","code":""},{"path":"https://persimune.github.io/explainer/reference/shapPartialPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"SHAP Partial Plot — ShapPartialPlot","text":"","code":"# \\donttest{ library(\"explainer\") seed <- 246 set.seed(seed) # Load necessary packages if (!requireNamespace(\"mlbench\", quietly = TRUE)) stop(\"mlbench not installed.\") if (!requireNamespace(\"mlr3learners\", quietly = TRUE)) stop(\"mlr3learners not installed.\") if (!requireNamespace(\"ranger\", quietly = TRUE)) stop(\"ranger not installed.\") # Load BreastCancer dataset utils::data(\"BreastCancer\", package = \"mlbench\") target_col <- \"Class\" positive_class <- \"malignant\" mydata <- BreastCancer[, -1] mydata <- na.omit(mydata) sex <- sample(   c(\"Male\", \"Female\"),   size = nrow(mydata),   replace = TRUE ) mydata$age <- as.numeric(sample(   seq(18, 60),   size = nrow(mydata),   replace = TRUE )) mydata$sex <- factor(   sex,   levels = c(\"Male\", \"Female\"),   labels = c(1, 0) ) maintask <- mlr3::TaskClassif$new(   id = \"my_classification_task\",   backend = mydata,   target = target_col,   positive = positive_class ) splits <- mlr3::partition(maintask) mylrn <- mlr3::lrn(   \"classif.ranger\",   predict_type = \"prob\" ) mylrn$train(maintask, splits$train) SHAP_output <- eSHAP_plot(   task = maintask,   trained_model = mylrn,   splits = splits,   sample.size = 2, # also 30 or more   seed = seed,   subset = 0.02 # up to 1 ) #> Error in ungroup(.): could not find function \"ungroup\" shap_Mean_long <- SHAP_output[[3]] #> Error: object 'SHAP_output' not found myplot <- ShapPartialPlot(shap_Mean_long) #> Error: object 'shap_Mean_long' not found # }"}]
